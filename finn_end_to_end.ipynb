{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70d89498f9b81b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T08:45:05.523417Z",
     "start_time": "2024-07-09T08:45:04.685297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: setuptools==69.5.1 in /tmp/home_dir/.local/lib/python3.10/site-packages (69.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools==69.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ea15791e7f1f909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T08:45:05.529942Z",
     "start_time": "2024-07-09T08:45:05.525537Z"
    }
   },
   "outputs": [],
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03933d3bb79454",
   "metadata": {},
   "source": [
    "<h1>Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T08:45:05.537794Z",
     "start_time": "2024-07-09T08:45:05.531683Z"
    }
   },
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "bits = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65857f6ea564333f",
   "metadata": {},
   "source": [
    "<h2>Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f815f89d03dc09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T08:45:05.607436Z",
     "start_time": "2024-07-09T08:45:05.539691Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa7a4c1f90f25d81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T08:45:05.868251Z",
     "start_time": "2024-07-09T08:45:05.610932Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'packaging' from 'pkg_resources' (/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbrevitas\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbrevitas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mqnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbrevitas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_qonnx\n",
      "File \u001b[0;32m/home/silas/PycharmProjects/finn/deps/brevitas/src/brevitas/__init__.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cpp_extension\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbrevitas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbrevitas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit \u001b[38;5;28;01mas\u001b[39;00m jit\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchVersion\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msetuptools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommand\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_ext\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpkg_resources\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packaging  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m IS_WINDOWS \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m IS_MACOS \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mplatform\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarwin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'packaging' from 'pkg_resources' (/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py)"
     ]
    }
   ],
   "source": [
    "import brevitas\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.export import export_qonnx\n",
    "from brevitas.quant import Int8Bias\n",
    "\n",
    "class QuantNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantNeuralNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.quant = qnn.QuantIdentity(bit_width=bits, return_quant_tensor=True)\n",
    "        self.linear1 = qnn.QuantLinear(in_features=28*28, out_features=512, bias=True, weight_bit_width=bits, bias_quant=Int8Bias)\n",
    "        self.relu1 = qnn.QuantReLU(bit_width=bits, return_quant_tensor=True)\n",
    "        self.linear2 = qnn.QuantLinear(in_features=512, out_features=512, bias=True, weigth_bit_width=bits, bias_quant=Int8Bias)\n",
    "        self.relu2 = qnn.QuantReLU(bit_width=bits, return_quant_tensor=True)\n",
    "        self.linear3 = qnn.QuantLinear(in_features=512, out_features=10, bias=True, weight_bit_width=bits, bias_quant=Int8Bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.quant(x)\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu2(out)\n",
    "        logits = self.linear3(out)\n",
    "        return logits\n",
    "\n",
    "model = QuantNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbea6facf9dc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f0792d0db403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed8ab58b520bf0",
   "metadata": {},
   "source": [
    "<h3>Train</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba49423673fda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a63b4e9e7bcac2",
   "metadata": {},
   "source": [
    "<h3>Export to qonnx</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead6153e3fc029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_qonnx_path = \"mnist_model_q.onnx\"\n",
    "input_shape = (1, 28, 28)\n",
    "export_qonnx(model, torch.randn(input_shape), export_qonnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67213f95ef12370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(export_qonnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebe4c74f37f096",
   "metadata": {},
   "source": [
    "<h1>Import trained PyTorch Model with ONNX<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56068fd216ea9a92",
   "metadata": {},
   "source": [
    "Cleanup transformation on QONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093c9353bae453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.util.cleanup import cleanup\n",
    "\n",
    "export_onnx_path_cleaned = \"mnist_model_q_clean.onnx\"\n",
    "cleanup(export_qonnx_path, out_file=export_onnx_path_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929c5e1ed8a892e",
   "metadata": {},
   "source": [
    "Import into FINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536275ebd5143ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import qonnx.core.onnx_exec as oxe\n",
    "import onnx.numpy_helper as nph\n",
    "import onnx.helper as onh\n",
    "import onnx\n",
    "\n",
    "sample_idx = torch.randint(len(test_data), size=(1,)).item()\n",
    "input_img, label = test_data[sample_idx]\n",
    "\n",
    "\n",
    "model = ModelWrapper(export_onnx_path_cleaned)\n",
    "input_dict = {\"global_in\": input_img.numpy()}\n",
    "output_dict = oxe.execute_onnx(model, input_dict)\n",
    "\n",
    "produced_qonnx = output_dict[list(output_dict.keys())[0]]\n",
    "\n",
    "produced_qonnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbb412774ca8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "plt.title(labels_map[produced_qonnx.argmax()])\n",
    "plt.imshow(input_img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b257b3c13fa940",
   "metadata": {},
   "source": [
    "<h2> Convert using QONNXtoFINN </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b9341607c7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "model.set_tensor_datatype(model.graph.input[0].name, DataType[\"\"])\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "export_onnx_path_converted = \"mnist_model_q_converted.onnx\"\n",
    "model.save(export_onnx_path_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444bf9dc7cdff51a",
   "metadata": {},
   "source": [
    "<h1> Launch a Build: Only Estimate Reports </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635eae5ab5998f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91299ba316e01cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"mnist_model_q_converted.onnx\"\n",
    "\n",
    "estimates_output_dir = \"output_estimates_only\"\n",
    "\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(estimates_output_dir):\n",
    "    shutil.rmtree(estimates_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "\n",
    "cfg_estimates = build.DataflowBuildConfig(\n",
    "    output_dir          = estimates_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7a35ticsg324-1L\",\n",
    "    steps               = build_cfg.estimate_only_dataflow_steps,\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd244f6ca62d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b39db615f8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(estimates_output_dir + \"/report/estimate_network_performance.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d4c93b5b07f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {estimates_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ca11d16cae62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {estimates_output_dir}/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01469e53ad6356",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat {estimates_output_dir}/report/estimate_network_performance.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be839884e4da897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json_dict(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        ret = json.load(f)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c72558a21f6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_cycles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4c67c55815f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_json_dict(estimates_output_dir + \"/report/estimate_layer_resources.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c921da061e586",
   "metadata": {},
   "source": [
    "<h2> Build Stitched IP </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b7c4f523e68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "model_file = \"mnist_model_q_converted.onnx\"\n",
    "\n",
    "rtlsim_output_dir = \"output_ipstitch_rtlsim\"\n",
    "\n",
    "#Delete previous run results if exist\n",
    "if os.path.exists(rtlsim_output_dir):\n",
    "    shutil.rmtree(rtlsim_output_dir)\n",
    "    print(\"Previous run results deleted!\")\n",
    "\n",
    "cfg_stitched_ip = build.DataflowBuildConfig(\n",
    "    output_dir          = rtlsim_output_dir,\n",
    "    mvau_wwidth_max     = 80,\n",
    "    target_fps          = 1000000,\n",
    "    synth_clk_period_ns = 10.0,\n",
    "    fpga_part           = \"xc7a35ticsg324-1L\",\n",
    "    generate_outputs=[\n",
    "        build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529f3779c7767ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "build.build_dataflow_cfg(model_file, cfg_stitched_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd35aeb92b4cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(\"cybersecurity/cybsec-mlp-ready.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
